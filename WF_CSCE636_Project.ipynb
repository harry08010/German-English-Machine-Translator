{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1zQTwsqbAW9"
   },
   "source": [
    "# **Machine Translation - CSCE 636 Project**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "The goal of this project is to implement a machine translation model. In the first step, a dataset of German to English terms will be used to train a translation model. The dataset can be accessed here:\n",
    "\n",
    "[German-English deu-eng.zip](http://www.manythings.org/anki/deu-eng.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CslsyjrebNzl"
   },
   "source": [
    "## **Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01Me3Cxpbqgt"
   },
   "outputs": [],
   "source": [
    "# Unzip the data file\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('deu-eng.zip', 'r')\n",
    "zip_ref.extractall('data-deu-eng')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvfCQYlxd0Kp"
   },
   "source": [
    "The file called deu.txt that contains 152,820 pairs of English to German phases, one pair per line with a tab separating the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "u8HyAM_td54x",
    "outputId": "fbf22c27-cb70-4836-ff02-97043687a229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi. Hallo! \n",
      "Hi. Grüß Gott! \n",
      "Run! Lauf! \n",
      "Wow! Potzdonner! \n",
      "Wow! Donnerwetter! \n"
     ]
    }
   ],
   "source": [
    "# First 5 lines of the deu.txt file\n",
    "import re\n",
    "with open(\"data-deu-eng/deu.txt\") as datafile:\n",
    "    head = [next(datafile) for x in range(5)]\n",
    "\n",
    "for pair in head:\n",
    "  print(re.sub('\\s+',' ',pair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GU8toYpDmWXd"
   },
   "source": [
    "## **Prepare the Text Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SF2H1l3Mmcau"
   },
   "source": [
    "Reviewing the raw data, there are some observations:\n",
    "* Punctuation;\n",
    "* Uppercase and lowercase; \n",
    "* Special characters in German; \n",
    "* Same phrases in English with different translations in German.\n",
    "\n",
    "Therefore, it is necessary to clean the data. So the data preparation is divided into two subsections:\n",
    "**clean text and split text**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KA3SI2UyoRMh"
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "import string\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8') # preserving the Unicode German characters\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITtyMtJ-n0m9"
   },
   "source": [
    "**1. Clean Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ims6_jcVofr2"
   },
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "\tlines = doc.strip().split('\\n')\n",
    "\tpairs = [line.split('\\t') for line in  lines] # seperate the English and German phrases\n",
    "\treturn pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcuEyEz-ozQ6"
   },
   "outputs": [],
   "source": [
    "# clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "\tcleaned = list()\n",
    "  \n",
    "\t# prepare regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor pair in lines:\n",
    "\t\tclean_pair = list()\n",
    "\t\tfor line in pair:\n",
    "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore') # normalize unicode characters\n",
    "\t\t\tline = line.decode('UTF-8')\n",
    "\t\t\tline = line.split()\n",
    "\t\t\tline = [word.translate(table) for word in line]         # remove punctuation from each token\n",
    "\t\t\tline = [re_print.sub('', w) for w in line]              # remove non-printable chars form each token\n",
    "\t\t\tline = [word for word in line if word.isalpha()]        # remove tokens with numbers in them\n",
    "\t\t\tclean_pair.append(' '.join(line))\n",
    "\t\tcleaned.append(clean_pair)\n",
    "\treturn array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1734
    },
    "colab_type": "code",
    "id": "Mbh_Fw8Cp3dF",
    "outputId": "f5694b30-4c83-4cdf-d7a7-e24eb093786a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-german.pkl\n",
      "[Hi] => [Hallo]\n",
      "[Hi] => [Gru Gott]\n",
      "[Run] => [Lauf]\n",
      "[Wow] => [Potzdonner]\n",
      "[Wow] => [Donnerwetter]\n",
      "[Fire] => [Feuer]\n",
      "[Help] => [Hilfe]\n",
      "[Help] => [Zu Hulf]\n",
      "[Stop] => [Stopp]\n",
      "[Wait] => [Warte]\n"
     ]
    }
   ],
   "source": [
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)\n",
    "\n",
    "# load dataset\n",
    "filename = 'data-deu-eng/deu.txt'\n",
    "doc = load_doc(filename)\n",
    "pairs = to_pairs(doc)\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "\n",
    "# save clean pairs to file\n",
    "save_clean_data(clean_pairs, 'english-german.pkl')\n",
    "\n",
    "# spot check\n",
    "for i in range(10):\n",
    "\tprint('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xc373GPvqx7t"
   },
   "source": [
    "**2. Split Text**\n",
    "\n",
    "The cleaned data now has over 150,000 phrase pairs. Here, the first 100,000 examples will be used - the first 80,000 examples for training and the remaining 20,000 for validation and testing, 10,000 for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gNiFIH06rloL",
    "outputId": "f3aa33b0-ab57-403e-ea32-b86d85ef7212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-german-both.pkl\n",
      "Saved: english-german-train.pkl\n",
      "Saved: english-german-vali.pkl\n",
      "Saved: english-german-test.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "\n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)\n",
    "\n",
    "raw_dataset = load_clean_sentences('english-german.pkl')\n",
    "\n",
    "# reduce dataset size\n",
    "n_sentences = 90000\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "shuffle(dataset)\n",
    "\n",
    "# split into train/test\n",
    "train, vali = dataset[:75000], dataset[75000:82500]\n",
    "test = dataset[82500:]\n",
    "# save training/testing data\n",
    "save_clean_data(dataset, 'english-german-both.pkl')\n",
    "save_clean_data(train, 'english-german-train.pkl')\n",
    "save_clean_data(vali, 'english-german-vali.pkl')\n",
    "save_clean_data(test, 'english-german-test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GBDXGdgKyRYc"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer\n",
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "\treturn max(len(line.split()) for line in lines)\n",
    "\n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "\t# integer encode sequences\n",
    "\tX = tokenizer.texts_to_sequences(lines)\n",
    "  \n",
    "\t# pad sequences with 0 values\n",
    "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
    "  \n",
    "\treturn X\n",
    "\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "\tylist = list()\n",
    "\tfor sequence in sequences:\n",
    "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "\t\tylist.append(encoded)\n",
    "\ty = array(ylist)\n",
    "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9118\n",
      "English Max Length: 9\n",
      "German Vocabulary Size: 16398\n",
      "German Max Length: 17\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "dataset = load_clean_sentences('english-german-both.pkl')\n",
    "train = load_clean_sentences('english-german-train.pkl')\n",
    "vali = load_clean_sentences('english-german-vali.pkl')\n",
    "test = load_clean_sentences('english-german-test.pkl')\n",
    "\n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])\n",
    "print('German Vocabulary Size: %d' % ger_vocab_size)\n",
    "print('German Max Length: %d' % (ger_length))\n",
    "\n",
    "# prepare training data\n",
    "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = encode_output(trainY, eng_vocab_size)\n",
    "\n",
    "# prepare validation data\n",
    "valiX = encode_sequences(ger_tokenizer, ger_length, vali[:, 1])\n",
    "valiY = encode_sequences(eng_tokenizer, eng_length, vali[:, 0])\n",
    "valiY = encode_output(valiY, eng_vocab_size)\n",
    "\n",
    "# prepare test data\n",
    "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "testY = encode_output(testY, eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2009
    },
    "colab_type": "code",
    "id": "u42mG-QVyjn3",
    "outputId": "bc48fdb5-abfc-463d-94ad-e3067b4e3660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 17, 256)           4197888   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 9, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 9, 9118)           2343326   \n",
      "=================================================================\n",
      "Total params: 7,591,838\n",
      "Trainable params: 7,591,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      " - 293s - loss: 4.0814 - acc: 0.4807 - val_loss: 3.5298 - val_acc: 0.4836\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.52981, saving model to model.h5\n",
      "Epoch 2/30\n",
      " - 292s - loss: 3.4115 - acc: 0.4982 - val_loss: 3.3416 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.52981 to 3.34165, saving model to model.h5\n",
      "Epoch 3/30\n",
      " - 295s - loss: 3.2856 - acc: 0.5095 - val_loss: 3.2593 - val_acc: 0.5143\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.34165 to 3.25934, saving model to model.h5\n",
      "Epoch 4/30\n",
      " - 290s - loss: 3.2142 - acc: 0.5140 - val_loss: 3.2088 - val_acc: 0.5197\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.25934 to 3.20875, saving model to model.h5\n",
      "Epoch 5/30\n",
      " - 296s - loss: 3.1666 - acc: 0.5195 - val_loss: 3.1794 - val_acc: 0.5227\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.20875 to 3.17939, saving model to model.h5\n",
      "Epoch 6/30\n",
      " - 302s - loss: 3.1222 - acc: 0.5283 - val_loss: 3.1287 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.17939 to 3.12871, saving model to model.h5\n",
      "Epoch 7/30\n",
      " - 292s - loss: 3.0523 - acc: 0.5423 - val_loss: 3.0728 - val_acc: 0.5443\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.12871 to 3.07275, saving model to model.h5\n",
      "Epoch 8/30\n",
      " - 291s - loss: 2.9837 - acc: 0.5456 - val_loss: 2.9995 - val_acc: 0.5454\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.07275 to 2.99947, saving model to model.h5\n",
      "Epoch 9/30\n",
      " - 289s - loss: 2.9073 - acc: 0.5508 - val_loss: 2.9227 - val_acc: 0.5558\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.99947 to 2.92274, saving model to model.h5\n",
      "Epoch 10/30\n",
      " - 290s - loss: 2.8127 - acc: 0.5644 - val_loss: 2.8435 - val_acc: 0.5655\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.92274 to 2.84345, saving model to model.h5\n",
      "Epoch 11/30\n",
      " - 290s - loss: 2.7222 - acc: 0.5741 - val_loss: 2.7634 - val_acc: 0.5764\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.84345 to 2.76343, saving model to model.h5\n",
      "Epoch 12/30\n",
      " - 289s - loss: 2.6245 - acc: 0.5861 - val_loss: 2.6776 - val_acc: 0.5878\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.76343 to 2.67759, saving model to model.h5\n",
      "Epoch 13/30\n",
      " - 289s - loss: 2.5193 - acc: 0.5997 - val_loss: 2.5811 - val_acc: 0.6008\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.67759 to 2.58112, saving model to model.h5\n",
      "Epoch 14/30\n",
      " - 288s - loss: 2.4093 - acc: 0.6127 - val_loss: 2.4980 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.58112 to 2.49804, saving model to model.h5\n",
      "Epoch 15/30\n",
      " - 289s - loss: 2.3016 - acc: 0.6260 - val_loss: 2.4140 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.49804 to 2.41402, saving model to model.h5\n",
      "Epoch 16/30\n",
      " - 289s - loss: 2.1973 - acc: 0.6383 - val_loss: 2.3341 - val_acc: 0.6290\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.41402 to 2.33409, saving model to model.h5\n",
      "Epoch 17/30\n",
      " - 288s - loss: 2.0948 - acc: 0.6489 - val_loss: 2.2538 - val_acc: 0.6384\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.33409 to 2.25383, saving model to model.h5\n",
      "Epoch 18/30\n",
      " - 288s - loss: 1.9940 - acc: 0.6587 - val_loss: 2.1755 - val_acc: 0.6446\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.25383 to 2.17551, saving model to model.h5\n",
      "Epoch 19/30\n",
      " - 289s - loss: 1.8966 - acc: 0.6680 - val_loss: 2.1106 - val_acc: 0.6487\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.17551 to 2.11061, saving model to model.h5\n",
      "Epoch 20/30\n",
      " - 291s - loss: 1.8034 - acc: 0.6765 - val_loss: 2.0436 - val_acc: 0.6556\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.11061 to 2.04363, saving model to model.h5\n",
      "Epoch 21/30\n",
      " - 289s - loss: 1.7095 - acc: 0.6858 - val_loss: 1.9879 - val_acc: 0.6629\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.04363 to 1.98789, saving model to model.h5\n",
      "Epoch 22/30\n",
      " - 290s - loss: 1.6210 - acc: 0.6941 - val_loss: 1.9241 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.98789 to 1.92412, saving model to model.h5\n",
      "Epoch 23/30\n",
      " - 289s - loss: 1.5378 - acc: 0.7026 - val_loss: 1.8725 - val_acc: 0.6718\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.92412 to 1.87252, saving model to model.h5\n",
      "Epoch 24/30\n",
      " - 289s - loss: 1.4549 - acc: 0.7117 - val_loss: 1.8276 - val_acc: 0.6766\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.87252 to 1.82756, saving model to model.h5\n",
      "Epoch 25/30\n",
      " - 289s - loss: 1.3785 - acc: 0.7202 - val_loss: 1.7864 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.82756 to 1.78640, saving model to model.h5\n",
      "Epoch 26/30\n",
      " - 290s - loss: 1.3035 - acc: 0.7294 - val_loss: 1.7544 - val_acc: 0.6868\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.78640 to 1.75437, saving model to model.h5\n",
      "Epoch 27/30\n",
      " - 289s - loss: 1.2326 - acc: 0.7387 - val_loss: 1.7152 - val_acc: 0.6876\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.75437 to 1.71517, saving model to model.h5\n",
      "Epoch 28/30\n",
      " - 289s - loss: 1.1647 - acc: 0.7480 - val_loss: 1.6779 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.71517 to 1.67789, saving model to model.h5\n",
      "Epoch 29/30\n",
      " - 289s - loss: 1.1024 - acc: 0.7574 - val_loss: 1.6589 - val_acc: 0.6986\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.67789 to 1.65889, saving model to model.h5\n",
      "Epoch 30/30\n",
      " - 293s - loss: 1.0443 - acc: 0.7663 - val_loss: 1.6270 - val_acc: 0.7024\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.65889 to 1.62699, saving model to model.h5\n"
     ]
    }
   ],
   "source": [
    "# define baseline NMT model\n",
    "def define_baseline_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "  model.add(LSTM(n_units))\n",
    "#   model.add(AttentionL(src_timesteps))\n",
    "  model.add(RepeatVector(tar_timesteps))\n",
    "  model.add(LSTM(n_units, return_sequences=True))\n",
    "  model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "  return model\n",
    "\n",
    "# define model\n",
    "model = define_baseline_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize defined model\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "# fit model\n",
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(trainX, trainY, epochs=30, batch_size=256, validation_data=(valiX, valiY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bidirectional model\n",
    "def define_bidirectional_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "  model.add(Bidirectional(LSTM(n_units, dropout=0.5)))\n",
    "  model.add(RepeatVector(tar_timesteps))\n",
    "  model.add(Bidirectional(LSTM(n_units, return_sequences=True, dropout=0.5)))\n",
    "  model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9118\n",
      "English Max Length: 9\n",
      "German Vocabulary Size: 16398\n",
      "German Max Length: 17\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 17, 256)           4197888   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               1050624   \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 9, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 9, 9118)           4677534   \n",
      "=================================================================\n",
      "Total params: 11,500,958\n",
      "Trainable params: 11,500,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 75000 samples, validate on 7500 samples\n",
      "Epoch 1/30\n",
      " - 454s - loss: 3.5551 - acc: 0.5082 - val_loss: 3.0879 - val_acc: 0.5321\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.08794, saving model to bi_model.h5\n",
      "Epoch 2/30\n",
      " - 452s - loss: 2.9402 - acc: 0.5463 - val_loss: 2.8342 - val_acc: 0.5554\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.08794 to 2.83420, saving model to bi_model.h5\n",
      "Epoch 3/30\n",
      " - 449s - loss: 2.6536 - acc: 0.5756 - val_loss: 2.5399 - val_acc: 0.5917\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.83420 to 2.53989, saving model to bi_model.h5\n",
      "Epoch 4/30\n",
      " - 449s - loss: 2.3476 - acc: 0.6112 - val_loss: 2.2483 - val_acc: 0.6286\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.53989 to 2.24826, saving model to bi_model.h5\n",
      "Epoch 5/30\n",
      " - 444s - loss: 2.0665 - acc: 0.6396 - val_loss: 2.0187 - val_acc: 0.6528\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.24826 to 2.01873, saving model to bi_model.h5\n",
      "Epoch 6/30\n",
      " - 444s - loss: 1.8366 - acc: 0.6613 - val_loss: 1.8444 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.01873 to 1.84439, saving model to bi_model.h5\n",
      "Epoch 7/30\n",
      " - 444s - loss: 1.6435 - acc: 0.6801 - val_loss: 1.7057 - val_acc: 0.6862\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.84439 to 1.70574, saving model to bi_model.h5\n",
      "Epoch 8/30\n",
      " - 449s - loss: 1.4809 - acc: 0.6967 - val_loss: 1.5998 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.70574 to 1.59984, saving model to bi_model.h5\n",
      "Epoch 9/30\n",
      " - 454s - loss: 1.3452 - acc: 0.7123 - val_loss: 1.5192 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.59984 to 1.51924, saving model to bi_model.h5\n",
      "Epoch 10/30\n",
      " - 452s - loss: 1.2313 - acc: 0.7271 - val_loss: 1.4496 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.51924 to 1.44956, saving model to bi_model.h5\n",
      "Epoch 11/30\n",
      " - 448s - loss: 1.1346 - acc: 0.7406 - val_loss: 1.3989 - val_acc: 0.7259\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.44956 to 1.39887, saving model to bi_model.h5\n",
      "Epoch 12/30\n",
      " - 445s - loss: 1.0521 - acc: 0.7537 - val_loss: 1.3634 - val_acc: 0.7301\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.39887 to 1.36340, saving model to bi_model.h5\n",
      "Epoch 13/30\n",
      " - 445s - loss: 0.9819 - acc: 0.7651 - val_loss: 1.3276 - val_acc: 0.7376\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.36340 to 1.32760, saving model to bi_model.h5\n",
      "Epoch 14/30\n",
      " - 444s - loss: 0.9202 - acc: 0.7760 - val_loss: 1.3012 - val_acc: 0.7437\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.32760 to 1.30117, saving model to bi_model.h5\n",
      "Epoch 15/30\n",
      " - 444s - loss: 0.8688 - acc: 0.7853 - val_loss: 1.2752 - val_acc: 0.7486\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.30117 to 1.27523, saving model to bi_model.h5\n",
      "Epoch 16/30\n",
      " - 444s - loss: 0.8223 - acc: 0.7939 - val_loss: 1.2592 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.27523 to 1.25917, saving model to bi_model.h5\n",
      "Epoch 17/30\n",
      " - 450s - loss: 0.7816 - acc: 0.8021 - val_loss: 1.2444 - val_acc: 0.7546\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.25917 to 1.24437, saving model to bi_model.h5\n",
      "Epoch 18/30\n",
      " - 444s - loss: 0.7476 - acc: 0.8086 - val_loss: 1.2363 - val_acc: 0.7563\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.24437 to 1.23630, saving model to bi_model.h5\n",
      "Epoch 19/30\n",
      " - 445s - loss: 0.7141 - acc: 0.8157 - val_loss: 1.2254 - val_acc: 0.7594\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.23630 to 1.22544, saving model to bi_model.h5\n",
      "Epoch 20/30\n",
      " - 453s - loss: 0.6864 - acc: 0.8208 - val_loss: 1.2171 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.22544 to 1.21705, saving model to bi_model.h5\n",
      "Epoch 21/30\n",
      " - 456s - loss: 0.6596 - acc: 0.8262 - val_loss: 1.2111 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.21705 to 1.21113, saving model to bi_model.h5\n",
      "Epoch 22/30\n",
      " - 452s - loss: 0.6355 - acc: 0.8312 - val_loss: 1.2102 - val_acc: 0.7635\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.21113 to 1.21025, saving model to bi_model.h5\n",
      "Epoch 23/30\n",
      " - 445s - loss: 0.6136 - acc: 0.8359 - val_loss: 1.1985 - val_acc: 0.7685\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.21025 to 1.19846, saving model to bi_model.h5\n",
      "Epoch 24/30\n",
      " - 464s - loss: 0.5930 - acc: 0.8400 - val_loss: 1.1960 - val_acc: 0.7703\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.19846 to 1.19596, saving model to bi_model.h5\n",
      "Epoch 25/30\n",
      " - 464s - loss: 0.5748 - acc: 0.8443 - val_loss: 1.1955 - val_acc: 0.7696\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.19596 to 1.19545, saving model to bi_model.h5\n",
      "Epoch 26/30\n",
      " - 462s - loss: 0.5571 - acc: 0.8480 - val_loss: 1.1965 - val_acc: 0.7711\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.19545\n",
      "Epoch 27/30\n",
      " - 464s - loss: 0.5412 - acc: 0.8516 - val_loss: 1.1972 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.19545\n",
      "Epoch 28/30\n",
      " - 461s - loss: 0.5258 - acc: 0.8545 - val_loss: 1.1957 - val_acc: 0.7720\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.19545\n",
      "Epoch 29/30\n",
      " - 462s - loss: 0.5109 - acc: 0.8578 - val_loss: 1.2001 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.19545\n",
      "Epoch 30/30\n",
      " - 461s - loss: 0.4978 - acc: 0.8609 - val_loss: 1.1977 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.19545\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])\n",
    "print('German Vocabulary Size: %d' % ger_vocab_size)\n",
    "print('German Max Length: %d' % (ger_length))\n",
    "\n",
    "bi_trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "bi_trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "bi_trainY = encode_output(bi_trainY, eng_vocab_size)\n",
    "\n",
    "# prepare validation data\n",
    "bi_valiX = encode_sequences(ger_tokenizer, ger_length, vali[:, 1])\n",
    "bi_valiY = encode_sequences(eng_tokenizer, eng_length, vali[:, 0])\n",
    "bi_valiY = encode_output(bi_valiY, eng_vocab_size)\n",
    "\n",
    "bi_testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    "bi_testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "bi_testY = encode_output(bi_testY, eng_vocab_size)\n",
    "\n",
    "bi_model = define_bidirectional_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
    "bi_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize defined model\n",
    "print(bi_model.summary())\n",
    "plot_model(bi_model, to_file='bi_model.png', show_shapes=True)\n",
    "\n",
    "# fit model\n",
    "filename = 'bi_model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "bi_history = bi_model.fit(bi_trainX, bi_trainY, epochs=30, batch_size=256, validation_data=(bi_valiX, bi_valiY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = bi_history.history['loss']\n",
    "val_loss = bi_history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AttentionMechanism import AttentionL\n",
    "# define attention model\n",
    "def define_attention_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "  model.add(Bidirectional(LSTM(n_units, return_sequences=True, dropout=0.5)))\n",
    "  model.add(AttentionL(src_timesteps))\n",
    "  model.add(RepeatVector(tar_timesteps))\n",
    "  model.add(Bidirectional(LSTM(n_units, return_sequences=True, dropout=0.5)))\n",
    "  model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9118\n",
      "English Max Length: 9\n",
      "German Vocabulary Size: 16398\n",
      "German Max Length: 17\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 17, 256)           4197888   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 17, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "attention_l_2 (AttentionL)   (None, 512)               529       \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 9, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 9, 9118)           4677534   \n",
      "=================================================================\n",
      "Total params: 11,501,487\n",
      "Trainable params: 11,501,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 75000 samples, validate on 7500 samples\n",
      "Epoch 1/30\n",
      " - 460s - loss: 3.5702 - acc: 0.5076 - val_loss: 3.1053 - val_acc: 0.5321\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.10529, saving model to attention_model.h5\n",
      "Epoch 2/30\n",
      " - 454s - loss: 2.9359 - acc: 0.5470 - val_loss: 2.8215 - val_acc: 0.5571\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.10529 to 2.82146, saving model to attention_model.h5\n",
      "Epoch 3/30\n",
      " - 454s - loss: 2.6563 - acc: 0.5758 - val_loss: 2.5584 - val_acc: 0.5894\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.82146 to 2.55836, saving model to attention_model.h5\n",
      "Epoch 4/30\n",
      " - 454s - loss: 2.3708 - acc: 0.6076 - val_loss: 2.2783 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.55836 to 2.27829, saving model to attention_model.h5\n",
      "Epoch 5/30\n",
      " - 453s - loss: 2.0901 - acc: 0.6372 - val_loss: 2.0436 - val_acc: 0.6503\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.27829 to 2.04356, saving model to attention_model.h5\n",
      "Epoch 6/30\n",
      " - 455s - loss: 1.8579 - acc: 0.6593 - val_loss: 1.8700 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.04356 to 1.86995, saving model to attention_model.h5\n",
      "Epoch 7/30\n",
      " - 458s - loss: 1.6694 - acc: 0.6768 - val_loss: 1.7341 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.86995 to 1.73412, saving model to attention_model.h5\n",
      "Epoch 8/30\n",
      " - 455s - loss: 1.5137 - acc: 0.6927 - val_loss: 1.6333 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.73412 to 1.63334, saving model to attention_model.h5\n",
      "Epoch 9/30\n",
      " - 453s - loss: 1.3831 - acc: 0.7067 - val_loss: 1.5484 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.63334 to 1.54838, saving model to attention_model.h5\n",
      "Epoch 10/30\n",
      " - 454s - loss: 1.2721 - acc: 0.7204 - val_loss: 1.4825 - val_acc: 0.7137\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.54838 to 1.48249, saving model to attention_model.h5\n",
      "Epoch 11/30\n",
      " - 454s - loss: 1.1757 - acc: 0.7335 - val_loss: 1.4316 - val_acc: 0.7211\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.48249 to 1.43159, saving model to attention_model.h5\n",
      "Epoch 12/30\n",
      " - 456s - loss: 1.0952 - acc: 0.7451 - val_loss: 1.3898 - val_acc: 0.7277\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.43159 to 1.38979, saving model to attention_model.h5\n",
      "Epoch 13/30\n",
      " - 455s - loss: 1.0242 - acc: 0.7566 - val_loss: 1.3573 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.38979 to 1.35729, saving model to attention_model.h5\n",
      "Epoch 14/30\n",
      " - 456s - loss: 0.9628 - acc: 0.7675 - val_loss: 1.3258 - val_acc: 0.7383\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.35729 to 1.32577, saving model to attention_model.h5\n",
      "Epoch 15/30\n",
      " - 454s - loss: 0.9092 - acc: 0.7773 - val_loss: 1.3033 - val_acc: 0.7422\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.32577 to 1.30334, saving model to attention_model.h5\n",
      "Epoch 16/30\n",
      " - 457s - loss: 0.8625 - acc: 0.7854 - val_loss: 1.2816 - val_acc: 0.7452\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.30334 to 1.28159, saving model to attention_model.h5\n",
      "Epoch 17/30\n",
      " - 463s - loss: 0.8200 - acc: 0.7940 - val_loss: 1.2689 - val_acc: 0.7488\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.28159 to 1.26889, saving model to attention_model.h5\n",
      "Epoch 18/30\n",
      " - 463s - loss: 0.7838 - acc: 0.8012 - val_loss: 1.2560 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.26889 to 1.25604, saving model to attention_model.h5\n",
      "Epoch 19/30\n",
      " - 459s - loss: 0.7501 - acc: 0.8074 - val_loss: 1.2436 - val_acc: 0.7539\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.25604 to 1.24356, saving model to attention_model.h5\n",
      "Epoch 20/30\n",
      " - 461s - loss: 0.7198 - acc: 0.8133 - val_loss: 1.2330 - val_acc: 0.7569\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.24356 to 1.23304, saving model to attention_model.h5\n",
      "Epoch 21/30\n",
      " - 463s - loss: 0.6928 - acc: 0.8185 - val_loss: 1.2249 - val_acc: 0.7599\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.23304 to 1.22489, saving model to attention_model.h5\n",
      "Epoch 22/30\n",
      " - 462s - loss: 0.6658 - acc: 0.8242 - val_loss: 1.2201 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.22489 to 1.22015, saving model to attention_model.h5\n",
      "Epoch 23/30\n",
      " - 459s - loss: 0.6438 - acc: 0.8286 - val_loss: 1.2142 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.22015 to 1.21422, saving model to attention_model.h5\n",
      "Epoch 24/30\n",
      " - 460s - loss: 0.6215 - acc: 0.8339 - val_loss: 1.2093 - val_acc: 0.7631\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.21422 to 1.20931, saving model to attention_model.h5\n",
      "Epoch 25/30\n",
      " - 460s - loss: 0.6013 - acc: 0.8378 - val_loss: 1.2091 - val_acc: 0.7639\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.20931 to 1.20912, saving model to attention_model.h5\n",
      "Epoch 26/30\n",
      " - 460s - loss: 0.5839 - acc: 0.8421 - val_loss: 1.2055 - val_acc: 0.7646\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.20912 to 1.20547, saving model to attention_model.h5\n",
      "Epoch 27/30\n",
      " - 460s - loss: 0.5653 - acc: 0.8455 - val_loss: 1.2054 - val_acc: 0.7685\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.20547 to 1.20536, saving model to attention_model.h5\n",
      "Epoch 28/30\n",
      " - 460s - loss: 0.5505 - acc: 0.8488 - val_loss: 1.2039 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.20536 to 1.20394, saving model to attention_model.h5\n",
      "Epoch 29/30\n",
      " - 462s - loss: 0.5344 - acc: 0.8520 - val_loss: 1.2032 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.20394 to 1.20325, saving model to attention_model.h5\n",
      "Epoch 30/30\n",
      " - 465s - loss: 0.5203 - acc: 0.8554 - val_loss: 1.2066 - val_acc: 0.7687\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.20325\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])\n",
    "print('German Vocabulary Size: %d' % ger_vocab_size)\n",
    "print('German Max Length: %d' % (ger_length))\n",
    "\n",
    "attention_trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "attention_trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "attention_trainY = encode_output(attention_trainY, eng_vocab_size)\n",
    "\n",
    "attention_valiX = encode_sequences(ger_tokenizer, ger_length, vali[:, 1])\n",
    "attention_valiY = encode_sequences(eng_tokenizer, eng_length, vali[:, 0])\n",
    "attention_valiY = encode_output(attention_valiY, eng_vocab_size)\n",
    "\n",
    "attention_testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    "attention_testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "attention_testY = encode_output(attention_testY, eng_vocab_size)\n",
    "\n",
    "attention_model = define_attention_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
    "attention_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize defined model\n",
    "print(attention_model.summary())\n",
    "plot_model(attention_model, to_file='attention_model.png', show_shapes=True)\n",
    "\n",
    "# fit model\n",
    "filename = 'attention_model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "attention_history = attention_model.fit(attention_trainX, attention_trainY, epochs=30, batch_size=256, validation_data=(attention_valiX, attention_valiY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = attention_history.history['loss']\n",
    "val_loss = attention_history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ou94F5LLzG41"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTO7C1gFzXhS"
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-dGUQGSzq9P"
   },
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oC56ziVqztlj"
   },
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "\tprediction = model.predict(source, verbose=0)[0]\n",
    "\tintegers = [argmax(vector) for vector in prediction]\n",
    "\ttarget = list()\n",
    "\tfor i in integers:\n",
    "\t\tword = word_for_id(i, tokenizer)\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\ttarget.append(word)\n",
    "\treturn ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gm8veHBhzwL6"
   },
   "outputs": [],
   "source": [
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "  smoothie = SmoothingFunction().method4\n",
    "  actual, predicted = list(), list()\n",
    "  correct_num = 0\n",
    "  total = 0\n",
    "  for i, source in enumerate(sources):\n",
    "    # translate encoded source text\n",
    "    source = source.reshape((1, source.shape[0]))\n",
    "    translation = predict_sequence(model, eng_tokenizer, source)\n",
    "    raw_target, raw_src = raw_dataset[i]\n",
    "    total += 1\n",
    "    if translation == raw_target.lower():\n",
    "      correct_num += 1\n",
    "    if i < 10:\n",
    "      print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "    actual.append(raw_target.split())\n",
    "    predicted.append(translation.split())\n",
    "\t# calculate BLEU score\n",
    "  print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0), smoothing_function=smoothie))\n",
    "  print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie))\n",
    "  print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0), smoothing_function=smoothie))\n",
    "  print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie))\n",
    "  # calculate accuracy\n",
    "  print(\"absolute accuracy=[%f], \" %float(correct_num / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "EXv2hWNszw-O",
    "outputId": "c615630d-ef33-4d72-8982-37b108f682c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading baseline model:\n",
      "train\n",
      "src=[Du hast echt n Knall], target=[Youre such a weirdo], predicted=[youre have a weirdo]\n",
      "src=[Da sind wir], target=[Here we are], predicted=[were we are]\n",
      "src=[Er ist in meiner Klasse], target=[Hes in my class], predicted=[hes in my my]\n",
      "src=[Er hatte die richtige Idee], target=[He had the right idea], predicted=[he was the plan]\n",
      "src=[Tom kam gut zu Hause an], target=[Tom arrived home safely], predicted=[tom arrived home home]\n",
      "src=[Ich habe mit dem Rauchen aufgehort], target=[I quit smoking], predicted=[i quit smoking smoking]\n",
      "src=[Macht euch keine Gedanken Ich sage nichts], target=[Dont worry I wont tell], predicted=[dont worry i i say]\n",
      "src=[Tom zerriss den Scheck], target=[Tom ripped up the check], predicted=[tom ripped up the]\n",
      "src=[Er ist an dieser Krankheit gestorben], target=[He died of that disease], predicted=[he died his his disease]\n",
      "src=[Er hat sich den Arm ausgerenkt], target=[He dislocated his arm], predicted=[he dislocated his arm]\n",
      "BLEU-1: 0.052111\n",
      "BLEU-2: 0.000690\n",
      "BLEU-3: 0.009731\n",
      "BLEU-4: 0.015485\n",
      "absolute accuracy=[0.432657], \n",
      "test\n",
      "src=[Das ist nie passiert], target=[This never happened], predicted=[everyone never happened]\n",
      "src=[Ich frage mich was geschehen wird], target=[I wonder what will happen], predicted=[i wonder what what]\n",
      "src=[Horen Sie auf sich wie ein Kind aufzufuhren], target=[Stop acting like a baby], predicted=[stop acting like a baby]\n",
      "src=[Habt ihr sie gesehen], target=[Have you seen her], predicted=[have you see them]\n",
      "src=[Willst du mitkommen], target=[Do you want to come along], predicted=[do you want to join]\n",
      "src=[Ich wei wo sie wohnt], target=[I know where she lives], predicted=[i know where you lives]\n",
      "src=[Lass mich sehen], target=[Let me see], predicted=[let me see]\n",
      "src=[Ich will das Mittagessen heute auslassen], target=[I plan to skip lunch], predicted=[i want an skipping lunch]\n",
      "src=[Das werden wir noch sehen], target=[That remains to be seen], predicted=[well see it]\n",
      "src=[Man hat mich angeschossen], target=[Ive been shot], predicted=[she had me me]\n",
      "BLEU-1: 0.053517\n",
      "BLEU-2: 0.191846\n",
      "BLEU-3: 0.283664\n",
      "BLEU-4: 0.256697\n",
      "absolute accuracy=[0.109533], \n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "print()\n",
    "print(\"Loading baseline model:\")\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# test on some training sequences\n",
    "print('train')\n",
    "evaluate_model(model, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(model, eng_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading bidirectional model:\n",
      "train\n",
      "src=[Tom hat geschummelt], target=[Tom was cheating], predicted=[tom cheated]\n",
      "src=[Ich flehe dich an mir zu helfen], target=[I beg you to help me], predicted=[i beg you to help me]\n",
      "src=[Tom ist wutend], target=[Tom is furious], predicted=[tom is furious]\n",
      "src=[Wir haben alles gesehen], target=[We saw everything], predicted=[we saw everything]\n",
      "src=[Ich sagte ich erinnere mich nicht], target=[I said I didnt remember], predicted=[i said i didnt remember]\n",
      "src=[Sie sollten sich einen Tag freinehmen], target=[You should take a day off], predicted=[you should take a day off]\n",
      "src=[Es gibt keine andere Erklarung], target=[Theres no other explanation], predicted=[theres no no other]\n",
      "src=[Das ist die Kamera meiner Schwester], target=[Thats my sisters camera], predicted=[this my sisters sisters]\n",
      "src=[Nehmen Sie die nachste Strae rechts], target=[Take the next right], predicted=[take the next right]\n",
      "src=[Das war unverzeihlich], target=[That was unforgivable], predicted=[that was unforgivable]\n",
      "BLEU-1: 0.048958\n",
      "BLEU-2: 0.187549\n",
      "BLEU-3: 0.281999\n",
      "BLEU-4: 0.256604\n",
      "absolute accuracy=[0.479533], \n",
      "test\n",
      "src=[Kann jemand anderes antworten], target=[Can anybody else answer], predicted=[can anyone answer answer]\n",
      "src=[Das Rad wird durch Wasserkraft angetrieben], target=[Water power turns the wheel], predicted=[the back is back complete]\n",
      "src=[Tom lehnte sich an die Wand], target=[Tom leaned against the wall], predicted=[tom leaned on the wall wall]\n",
      "src=[Wir werden es uns ansehen], target=[Well take a look], predicted=[well get it]\n",
      "src=[Sie gewinnen], target=[Youre winning], predicted=[they winning]\n",
      "src=[Es ist sich niemand so ganz sicher], target=[Nobody is really sure], predicted=[it no no that true]\n",
      "src=[Maria hat kein Selbstwertgefuhl], target=[Mary has no selfesteem], predicted=[mary has not]\n",
      "src=[Ich besuchte mit Tom ein Konzert], target=[I went to a concert with Tom], predicted=[i went to with work tom]\n",
      "src=[Ich kam auf einen Gedanken], target=[I hit on an idea], predicted=[i was about]\n",
      "src=[Hat Tom etwas zu Abend gegessen], target=[Did Tom eat dinner], predicted=[did tom eaten dinner dinner]\n",
      "BLEU-1: 0.049230\n",
      "BLEU-2: 0.182429\n",
      "BLEU-3: 0.274385\n",
      "BLEU-4: 0.249228\n",
      "absolute accuracy=[0.184667], \n"
     ]
    }
   ],
   "source": [
    "# load bidirectional model\n",
    "print()\n",
    "print(\"Loading bidirectional model:\")\n",
    "bi_model = load_model('bi_model.h5')\n",
    "print('train')\n",
    "evaluate_model(bi_model, eng_tokenizer, bi_trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(bi_model, eng_tokenizer, bi_testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading attention model:\n",
      "train\n",
      "src=[Tom hat geschummelt], target=[Tom was cheating], predicted=[tom cheated]\n",
      "src=[Ich flehe dich an mir zu helfen], target=[I beg you to help me], predicted=[i beg you to help me]\n",
      "src=[Tom ist wutend], target=[Tom is furious], predicted=[tom is infuriated]\n",
      "src=[Wir haben alles gesehen], target=[We saw everything], predicted=[we saw everything]\n",
      "src=[Ich sagte ich erinnere mich nicht], target=[I said I didnt remember], predicted=[i said i didnt remember]\n",
      "src=[Sie sollten sich einen Tag freinehmen], target=[You should take a day off], predicted=[you should take a day off]\n",
      "src=[Es gibt keine andere Erklarung], target=[Theres no other explanation], predicted=[theres no other explanation]\n",
      "src=[Das ist die Kamera meiner Schwester], target=[Thats my sisters camera], predicted=[this is sisters sisters camera]\n",
      "src=[Nehmen Sie die nachste Strae rechts], target=[Take the next right], predicted=[take the next next right]\n",
      "src=[Das war unverzeihlich], target=[That was unforgivable], predicted=[that was unforgivable]\n",
      "BLEU-1: 0.050183\n",
      "BLEU-2: 0.189880\n",
      "BLEU-3: 0.284097\n",
      "BLEU-4: 0.258194\n",
      "absolute accuracy=[0.510400], \n",
      "test\n",
      "src=[Kann jemand anderes antworten], target=[Can anybody else answer], predicted=[can anyone know know]\n",
      "src=[Das Rad wird durch Wasserkraft angetrieben], target=[Water power turns the wheel], predicted=[the meeting started be by]\n",
      "src=[Tom lehnte sich an die Wand], target=[Tom leaned against the wall], predicted=[tom leaned on the wall]\n",
      "src=[Wir werden es uns ansehen], target=[Well take a look], predicted=[well look to]\n",
      "src=[Sie gewinnen], target=[Youre winning], predicted=[they winning]\n",
      "src=[Es ist sich niemand so ganz sicher], target=[Nobody is really sure], predicted=[its no but sure]\n",
      "src=[Maria hat kein Selbstwertgefuhl], target=[Mary has no selfesteem], predicted=[mary has no]\n",
      "src=[Ich besuchte mit Tom ein Konzert], target=[I went to a concert with Tom], predicted=[i went to to a tom]\n",
      "src=[Ich kam auf einen Gedanken], target=[I hit on an idea], predicted=[i came a]\n",
      "src=[Hat Tom etwas zu Abend gegessen], target=[Did Tom eat dinner], predicted=[did tom propose dinner]\n",
      "BLEU-1: 0.050748\n",
      "BLEU-2: 0.185214\n",
      "BLEU-3: 0.276888\n",
      "BLEU-4: 0.251119\n",
      "absolute accuracy=[0.193733], \n"
     ]
    }
   ],
   "source": [
    "# load attention model\n",
    "print()\n",
    "print(\"Loading attention model:\")\n",
    "attention_model = load_model('attention_model.h5', custom_objects={'AttentionL':AttentionL})\n",
    "print('train')\n",
    "evaluate_model(attention_model, eng_tokenizer, attention_trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(attention_model, eng_tokenizer, attention_testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW2DhSQO9bsy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer exported\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open('ger_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(ger_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('eng_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(eng_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"tokenizer exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WF_CSCE636_Project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
