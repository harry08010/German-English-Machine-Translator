{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1zQTwsqbAW9"
   },
   "source": [
    "# **Machine Translation - CSCE 636 Project**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "The goal of this project is to implement a machine translation model. In the first step, a dataset of German to English terms will be used to train a translation model. The dataset can be accessed here:\n",
    "\n",
    "[German-English deu-eng.zip](http://www.manythings.org/anki/deu-eng.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CslsyjrebNzl"
   },
   "source": [
    "## **Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01Me3Cxpbqgt"
   },
   "outputs": [],
   "source": [
    "# Unzip the data file\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('deu-eng.zip', 'r')\n",
    "zip_ref.extractall('data-deu-eng')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvfCQYlxd0Kp"
   },
   "source": [
    "The file called deu.txt that contains 152,820 pairs of English to German phases, one pair per line with a tab separating the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "u8HyAM_td54x",
    "outputId": "fbf22c27-cb70-4836-ff02-97043687a229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi. Hallo! \n",
      "Hi. Grüß Gott! \n",
      "Run! Lauf! \n",
      "Wow! Potzdonner! \n",
      "Wow! Donnerwetter! \n"
     ]
    }
   ],
   "source": [
    "# First 5 lines of the deu.txt file\n",
    "import re\n",
    "with open(\"data-deu-eng/deu.txt\") as datafile:\n",
    "    head = [next(datafile) for x in range(5)]\n",
    "\n",
    "for pair in head:\n",
    "  print(re.sub('\\s+',' ',pair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GU8toYpDmWXd"
   },
   "source": [
    "## **Prepare the Text Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SF2H1l3Mmcau"
   },
   "source": [
    "Reviewing the raw data, there are some observations:\n",
    "* Punctuation;\n",
    "* Uppercase and lowercase; \n",
    "* Special characters in German; \n",
    "* Same phrases in English with different translations in German.\n",
    "\n",
    "Therefore, it is necessary to clean the data. So the data preparation is divided into two subsections:\n",
    "**clean text and split text**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KA3SI2UyoRMh"
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "import string\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8') # preserving the Unicode German characters\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITtyMtJ-n0m9"
   },
   "source": [
    "**1. Clean Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ims6_jcVofr2"
   },
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "\tlines = doc.strip().split('\\n')\n",
    "\tpairs = [line.split('\\t') for line in  lines] # seperate the English and German phrases\n",
    "\treturn pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcuEyEz-ozQ6"
   },
   "outputs": [],
   "source": [
    "# clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "\tcleaned = list()\n",
    "  \n",
    "\t# prepare regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor pair in lines:\n",
    "\t\tclean_pair = list()\n",
    "\t\tfor line in pair:\n",
    "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore') # normalize unicode characters\n",
    "\t\t\tline = line.decode('UTF-8')\n",
    "\t\t\tline = line.split()\n",
    "\t\t\tline = [word.translate(table) for word in line]         # remove punctuation from each token\n",
    "\t\t\tline = [re_print.sub('', w) for w in line]              # remove non-printable chars form each token\n",
    "\t\t\tline = [word for word in line if word.isalpha()]        # remove tokens with numbers in them\n",
    "\t\t\tclean_pair.append(' '.join(line))\n",
    "\t\tcleaned.append(clean_pair)\n",
    "\treturn array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1734
    },
    "colab_type": "code",
    "id": "Mbh_Fw8Cp3dF",
    "outputId": "f5694b30-4c83-4cdf-d7a7-e24eb093786a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-german.pkl\n",
      "[Hi] => [Hallo]\n",
      "[Hi] => [Gru Gott]\n",
      "[Run] => [Lauf]\n",
      "[Wow] => [Potzdonner]\n",
      "[Wow] => [Donnerwetter]\n",
      "[Fire] => [Feuer]\n",
      "[Help] => [Hilfe]\n",
      "[Help] => [Zu Hulf]\n",
      "[Stop] => [Stopp]\n",
      "[Wait] => [Warte]\n"
     ]
    }
   ],
   "source": [
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)\n",
    "\n",
    "# load dataset\n",
    "filename = 'data-deu-eng/deu.txt'\n",
    "doc = load_doc(filename)\n",
    "pairs = to_pairs(doc)\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "\n",
    "# save clean pairs to file\n",
    "save_clean_data(clean_pairs, 'english-german.pkl')\n",
    "\n",
    "# spot check\n",
    "for i in range(10):\n",
    "\tprint('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xc373GPvqx7t"
   },
   "source": [
    "**2. Split Text**\n",
    "\n",
    "The cleaned data now has over 150,000 phrase pairs. Here, the first 100,000 examples will be used - the first 80,000 examples for training and the remaining 20,000 for validation and testing, 10,000 for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gNiFIH06rloL",
    "outputId": "f3aa33b0-ab57-403e-ea32-b86d85ef7212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-german-both.pkl\n",
      "Saved: english-german-train.pkl\n",
      "Saved: english-german-vali.pkl\n",
      "Saved: english-german-test.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "\n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)\n",
    "\n",
    "raw_dataset = load_clean_sentences('english-german.pkl')\n",
    "\n",
    "# reduce dataset size\n",
    "n_sentences = 90000\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "shuffle(dataset)\n",
    "\n",
    "# split into train/test\n",
    "train, vali = dataset[:75000], dataset[75000:82500]\n",
    "test = dataset[82500:]\n",
    "# save training/testing data\n",
    "save_clean_data(dataset, 'english-german-both.pkl')\n",
    "save_clean_data(train, 'english-german-train.pkl')\n",
    "save_clean_data(vali, 'english-german-vali.pkl')\n",
    "save_clean_data(test, 'english-german-test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GBDXGdgKyRYc"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Activation\n",
    "from attention_decoder import AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer\n",
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "\treturn max(len(line.split()) for line in lines)\n",
    "\n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "\t# integer encode sequences\n",
    "\tX = tokenizer.texts_to_sequences(lines)\n",
    "  \n",
    "\t# pad sequences with 0 values\n",
    "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
    "  \n",
    "\treturn X\n",
    "\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "\tylist = list()\n",
    "\tfor sequence in sequences:\n",
    "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "\t\tylist.append(encoded)\n",
    "\ty = array(ylist)\n",
    "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9118\n",
      "English Max Length: 9\n",
      "German Vocabulary Size: 16398\n",
      "German Max Length: 17\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "dataset = load_clean_sentences('english-german-both.pkl')\n",
    "train = load_clean_sentences('english-german-train.pkl')\n",
    "vali = load_clean_sentences('english-german-vali.pkl')\n",
    "test = load_clean_sentences('english-german-test.pkl')\n",
    "\n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])\n",
    "print('German Vocabulary Size: %d' % ger_vocab_size)\n",
    "print('German Max Length: %d' % (ger_length))\n",
    "\n",
    "# prepare training data\n",
    "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = encode_output(trainY, eng_vocab_size)\n",
    "\n",
    "# prepare validation data\n",
    "valiX = encode_sequences(ger_tokenizer, ger_length, vali[:, 1])\n",
    "valiY = encode_sequences(eng_tokenizer, eng_length, vali[:, 0])\n",
    "valiY = encode_output(valiY, eng_vocab_size)\n",
    "\n",
    "# prepare test data\n",
    "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "testY = encode_output(testY, eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2009
    },
    "colab_type": "code",
    "id": "u42mG-QVyjn3",
    "outputId": "bc48fdb5-abfc-463d-94ad-e3067b4e3660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 17, 256)           4197888   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 9, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 9, 9118)           2343326   \n",
      "=================================================================\n",
      "Total params: 7,591,838\n",
      "Trainable params: 7,591,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      " - 293s - loss: 4.0814 - acc: 0.4807 - val_loss: 3.5298 - val_acc: 0.4836\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.52981, saving model to model.h5\n",
      "Epoch 2/30\n",
      " - 292s - loss: 3.4115 - acc: 0.4982 - val_loss: 3.3416 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.52981 to 3.34165, saving model to model.h5\n",
      "Epoch 3/30\n",
      " - 295s - loss: 3.2856 - acc: 0.5095 - val_loss: 3.2593 - val_acc: 0.5143\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.34165 to 3.25934, saving model to model.h5\n",
      "Epoch 4/30\n",
      " - 290s - loss: 3.2142 - acc: 0.5140 - val_loss: 3.2088 - val_acc: 0.5197\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.25934 to 3.20875, saving model to model.h5\n",
      "Epoch 5/30\n",
      " - 296s - loss: 3.1666 - acc: 0.5195 - val_loss: 3.1794 - val_acc: 0.5227\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.20875 to 3.17939, saving model to model.h5\n",
      "Epoch 6/30\n",
      " - 302s - loss: 3.1222 - acc: 0.5283 - val_loss: 3.1287 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.17939 to 3.12871, saving model to model.h5\n",
      "Epoch 7/30\n",
      " - 292s - loss: 3.0523 - acc: 0.5423 - val_loss: 3.0728 - val_acc: 0.5443\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.12871 to 3.07275, saving model to model.h5\n",
      "Epoch 8/30\n",
      " - 291s - loss: 2.9837 - acc: 0.5456 - val_loss: 2.9995 - val_acc: 0.5454\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.07275 to 2.99947, saving model to model.h5\n",
      "Epoch 9/30\n",
      " - 289s - loss: 2.9073 - acc: 0.5508 - val_loss: 2.9227 - val_acc: 0.5558\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.99947 to 2.92274, saving model to model.h5\n",
      "Epoch 10/30\n",
      " - 290s - loss: 2.8127 - acc: 0.5644 - val_loss: 2.8435 - val_acc: 0.5655\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.92274 to 2.84345, saving model to model.h5\n",
      "Epoch 11/30\n",
      " - 290s - loss: 2.7222 - acc: 0.5741 - val_loss: 2.7634 - val_acc: 0.5764\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.84345 to 2.76343, saving model to model.h5\n",
      "Epoch 12/30\n",
      " - 289s - loss: 2.6245 - acc: 0.5861 - val_loss: 2.6776 - val_acc: 0.5878\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.76343 to 2.67759, saving model to model.h5\n",
      "Epoch 13/30\n",
      " - 289s - loss: 2.5193 - acc: 0.5997 - val_loss: 2.5811 - val_acc: 0.6008\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.67759 to 2.58112, saving model to model.h5\n",
      "Epoch 14/30\n",
      " - 288s - loss: 2.4093 - acc: 0.6127 - val_loss: 2.4980 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.58112 to 2.49804, saving model to model.h5\n",
      "Epoch 15/30\n",
      " - 289s - loss: 2.3016 - acc: 0.6260 - val_loss: 2.4140 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.49804 to 2.41402, saving model to model.h5\n",
      "Epoch 16/30\n",
      " - 289s - loss: 2.1973 - acc: 0.6383 - val_loss: 2.3341 - val_acc: 0.6290\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.41402 to 2.33409, saving model to model.h5\n",
      "Epoch 17/30\n",
      " - 288s - loss: 2.0948 - acc: 0.6489 - val_loss: 2.2538 - val_acc: 0.6384\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.33409 to 2.25383, saving model to model.h5\n",
      "Epoch 18/30\n",
      " - 288s - loss: 1.9940 - acc: 0.6587 - val_loss: 2.1755 - val_acc: 0.6446\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.25383 to 2.17551, saving model to model.h5\n",
      "Epoch 19/30\n",
      " - 289s - loss: 1.8966 - acc: 0.6680 - val_loss: 2.1106 - val_acc: 0.6487\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.17551 to 2.11061, saving model to model.h5\n",
      "Epoch 20/30\n",
      " - 291s - loss: 1.8034 - acc: 0.6765 - val_loss: 2.0436 - val_acc: 0.6556\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.11061 to 2.04363, saving model to model.h5\n",
      "Epoch 21/30\n",
      " - 289s - loss: 1.7095 - acc: 0.6858 - val_loss: 1.9879 - val_acc: 0.6629\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.04363 to 1.98789, saving model to model.h5\n",
      "Epoch 22/30\n",
      " - 290s - loss: 1.6210 - acc: 0.6941 - val_loss: 1.9241 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.98789 to 1.92412, saving model to model.h5\n",
      "Epoch 23/30\n",
      " - 289s - loss: 1.5378 - acc: 0.7026 - val_loss: 1.8725 - val_acc: 0.6718\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.92412 to 1.87252, saving model to model.h5\n",
      "Epoch 24/30\n",
      " - 289s - loss: 1.4549 - acc: 0.7117 - val_loss: 1.8276 - val_acc: 0.6766\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.87252 to 1.82756, saving model to model.h5\n",
      "Epoch 25/30\n",
      " - 289s - loss: 1.3785 - acc: 0.7202 - val_loss: 1.7864 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.82756 to 1.78640, saving model to model.h5\n",
      "Epoch 26/30\n",
      " - 290s - loss: 1.3035 - acc: 0.7294 - val_loss: 1.7544 - val_acc: 0.6868\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.78640 to 1.75437, saving model to model.h5\n",
      "Epoch 27/30\n",
      " - 289s - loss: 1.2326 - acc: 0.7387 - val_loss: 1.7152 - val_acc: 0.6876\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.75437 to 1.71517, saving model to model.h5\n",
      "Epoch 28/30\n",
      " - 289s - loss: 1.1647 - acc: 0.7480 - val_loss: 1.6779 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.71517 to 1.67789, saving model to model.h5\n",
      "Epoch 29/30\n",
      " - 289s - loss: 1.1024 - acc: 0.7574 - val_loss: 1.6589 - val_acc: 0.6986\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.67789 to 1.65889, saving model to model.h5\n",
      "Epoch 30/30\n",
      " - 293s - loss: 1.0443 - acc: 0.7663 - val_loss: 1.6270 - val_acc: 0.7024\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.65889 to 1.62699, saving model to model.h5\n"
     ]
    }
   ],
   "source": [
    "# define baseline NMT model\n",
    "def define_baseline_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "  model.add(LSTM(n_units))\n",
    "#   model.add(AttentionL(src_timesteps))\n",
    "  model.add(RepeatVector(tar_timesteps))\n",
    "  model.add(LSTM(n_units, return_sequences=True))\n",
    "  model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "  return model\n",
    "\n",
    "# define model\n",
    "model = define_baseline_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize defined model\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "# fit model\n",
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(trainX, trainY, epochs=30, batch_size=256, validation_data=(valiX, valiY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bidirectional model\n",
    "def define_bidirectional_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "  model.add(Bidirectional(LSTM(n_units, dropout=0.5)))\n",
    "  model.add(RepeatVector(tar_timesteps))\n",
    "  model.add(Bidirectional(LSTM(n_units, return_sequences=True, dropout=0.5)))\n",
    "  model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9118\n",
      "English Max Length: 9\n",
      "German Vocabulary Size: 16398\n",
      "German Max Length: 17\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 17, 256)           4197888   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               1050624   \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 9, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 9, 9118)           4677534   \n",
      "=================================================================\n",
      "Total params: 11,500,958\n",
      "Trainable params: 11,500,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 75000 samples, validate on 7500 samples\n",
      "Epoch 1/30\n",
      " - 454s - loss: 3.5551 - acc: 0.5082 - val_loss: 3.0879 - val_acc: 0.5321\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.08794, saving model to bi_model.h5\n",
      "Epoch 2/30\n",
      " - 452s - loss: 2.9402 - acc: 0.5463 - val_loss: 2.8342 - val_acc: 0.5554\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.08794 to 2.83420, saving model to bi_model.h5\n",
      "Epoch 3/30\n",
      " - 449s - loss: 2.6536 - acc: 0.5756 - val_loss: 2.5399 - val_acc: 0.5917\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.83420 to 2.53989, saving model to bi_model.h5\n",
      "Epoch 4/30\n",
      " - 449s - loss: 2.3476 - acc: 0.6112 - val_loss: 2.2483 - val_acc: 0.6286\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.53989 to 2.24826, saving model to bi_model.h5\n",
      "Epoch 5/30\n",
      " - 444s - loss: 2.0665 - acc: 0.6396 - val_loss: 2.0187 - val_acc: 0.6528\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.24826 to 2.01873, saving model to bi_model.h5\n",
      "Epoch 6/30\n",
      " - 444s - loss: 1.8366 - acc: 0.6613 - val_loss: 1.8444 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.01873 to 1.84439, saving model to bi_model.h5\n",
      "Epoch 7/30\n",
      " - 444s - loss: 1.6435 - acc: 0.6801 - val_loss: 1.7057 - val_acc: 0.6862\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.84439 to 1.70574, saving model to bi_model.h5\n",
      "Epoch 8/30\n",
      " - 449s - loss: 1.4809 - acc: 0.6967 - val_loss: 1.5998 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.70574 to 1.59984, saving model to bi_model.h5\n",
      "Epoch 9/30\n",
      " - 454s - loss: 1.3452 - acc: 0.7123 - val_loss: 1.5192 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.59984 to 1.51924, saving model to bi_model.h5\n",
      "Epoch 10/30\n",
      " - 452s - loss: 1.2313 - acc: 0.7271 - val_loss: 1.4496 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.51924 to 1.44956, saving model to bi_model.h5\n",
      "Epoch 11/30\n",
      " - 448s - loss: 1.1346 - acc: 0.7406 - val_loss: 1.3989 - val_acc: 0.7259\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.44956 to 1.39887, saving model to bi_model.h5\n",
      "Epoch 12/30\n",
      " - 445s - loss: 1.0521 - acc: 0.7537 - val_loss: 1.3634 - val_acc: 0.7301\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.39887 to 1.36340, saving model to bi_model.h5\n",
      "Epoch 13/30\n",
      " - 445s - loss: 0.9819 - acc: 0.7651 - val_loss: 1.3276 - val_acc: 0.7376\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.36340 to 1.32760, saving model to bi_model.h5\n",
      "Epoch 14/30\n",
      " - 444s - loss: 0.9202 - acc: 0.7760 - val_loss: 1.3012 - val_acc: 0.7437\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.32760 to 1.30117, saving model to bi_model.h5\n",
      "Epoch 15/30\n",
      " - 444s - loss: 0.8688 - acc: 0.7853 - val_loss: 1.2752 - val_acc: 0.7486\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.30117 to 1.27523, saving model to bi_model.h5\n",
      "Epoch 16/30\n",
      " - 444s - loss: 0.8223 - acc: 0.7939 - val_loss: 1.2592 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.27523 to 1.25917, saving model to bi_model.h5\n",
      "Epoch 17/30\n",
      " - 450s - loss: 0.7816 - acc: 0.8021 - val_loss: 1.2444 - val_acc: 0.7546\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.25917 to 1.24437, saving model to bi_model.h5\n",
      "Epoch 18/30\n",
      " - 444s - loss: 0.7476 - acc: 0.8086 - val_loss: 1.2363 - val_acc: 0.7563\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.24437 to 1.23630, saving model to bi_model.h5\n",
      "Epoch 19/30\n",
      " - 445s - loss: 0.7141 - acc: 0.8157 - val_loss: 1.2254 - val_acc: 0.7594\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.23630 to 1.22544, saving model to bi_model.h5\n",
      "Epoch 20/30\n",
      " - 453s - loss: 0.6864 - acc: 0.8208 - val_loss: 1.2171 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.22544 to 1.21705, saving model to bi_model.h5\n",
      "Epoch 21/30\n",
      " - 456s - loss: 0.6596 - acc: 0.8262 - val_loss: 1.2111 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.21705 to 1.21113, saving model to bi_model.h5\n",
      "Epoch 22/30\n",
      " - 452s - loss: 0.6355 - acc: 0.8312 - val_loss: 1.2102 - val_acc: 0.7635\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.21113 to 1.21025, saving model to bi_model.h5\n",
      "Epoch 23/30\n",
      " - 445s - loss: 0.6136 - acc: 0.8359 - val_loss: 1.1985 - val_acc: 0.7685\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.21025 to 1.19846, saving model to bi_model.h5\n",
      "Epoch 24/30\n",
      " - 464s - loss: 0.5930 - acc: 0.8400 - val_loss: 1.1960 - val_acc: 0.7703\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.19846 to 1.19596, saving model to bi_model.h5\n",
      "Epoch 25/30\n",
      " - 464s - loss: 0.5748 - acc: 0.8443 - val_loss: 1.1955 - val_acc: 0.7696\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.19596 to 1.19545, saving model to bi_model.h5\n",
      "Epoch 26/30\n",
      " - 462s - loss: 0.5571 - acc: 0.8480 - val_loss: 1.1965 - val_acc: 0.7711\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.19545\n",
      "Epoch 27/30\n",
      " - 464s - loss: 0.5412 - acc: 0.8516 - val_loss: 1.1972 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.19545\n",
      "Epoch 28/30\n",
      " - 461s - loss: 0.5258 - acc: 0.8545 - val_loss: 1.1957 - val_acc: 0.7720\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.19545\n",
      "Epoch 29/30\n",
      " - 462s - loss: 0.5109 - acc: 0.8578 - val_loss: 1.2001 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.19545\n",
      "Epoch 30/30\n",
      " - 461s - loss: 0.4978 - acc: 0.8609 - val_loss: 1.1977 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.19545\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])\n",
    "print('German Vocabulary Size: %d' % ger_vocab_size)\n",
    "print('German Max Length: %d' % (ger_length))\n",
    "\n",
    "bi_trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "bi_trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "bi_trainY = encode_output(bi_trainY, eng_vocab_size)\n",
    "\n",
    "# prepare validation data\n",
    "bi_valiX = encode_sequences(ger_tokenizer, ger_length, vali[:, 1])\n",
    "bi_valiY = encode_sequences(eng_tokenizer, eng_length, vali[:, 0])\n",
    "bi_valiY = encode_output(bi_valiY, eng_vocab_size)\n",
    "\n",
    "bi_testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    "bi_testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "bi_testY = encode_output(bi_testY, eng_vocab_size)\n",
    "\n",
    "bi_model = define_bidirectional_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
    "bi_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize defined model\n",
    "print(bi_model.summary())\n",
    "plot_model(bi_model, to_file='bi_model.png', show_shapes=True)\n",
    "\n",
    "# fit model\n",
    "filename = 'bi_model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "bi_history = bi_model.fit(bi_trainX, bi_trainY, epochs=30, batch_size=256, validation_data=(bi_valiX, bi_valiY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = bi_history.history['loss']\n",
    "val_loss = bi_history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AttentionMechanism import AttentionL\n",
    "# define attention model\n",
    "def define_attention_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "  model.add(Bidirectional(LSTM(n_units, return_sequences=True, dropout=0.5)))\n",
    "  model.add(AttentionL(src_timesteps))\n",
    "  model.add(RepeatVector(tar_timesteps))\n",
    "  model.add(Bidirectional(LSTM(n_units, return_sequences=True, dropout=0.5)))\n",
    "  model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9118\n",
      "English Max Length: 9\n",
      "German Vocabulary Size: 16398\n",
      "German Max Length: 17\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 17, 256)           4197888   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 17, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "attention_l_1 (AttentionL)   (None, 512)               529       \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 9, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 9, 9118)           4677534   \n",
      "=================================================================\n",
      "Total params: 11,501,487\n",
      "Trainable params: 11,501,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 75000 samples, validate on 7500 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6f1910c8243c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'attention_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mattention_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_trainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_trainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_valiX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_valiY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])\n",
    "print('German Vocabulary Size: %d' % ger_vocab_size)\n",
    "print('German Max Length: %d' % (ger_length))\n",
    "\n",
    "attention_trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "attention_trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "attention_trainY = encode_output(attention_trainY, eng_vocab_size)\n",
    "\n",
    "attention_valiX = encode_sequences(ger_tokenizer, ger_length, vali[:, 1])\n",
    "attention_valiY = encode_sequences(eng_tokenizer, eng_length, vali[:, 0])\n",
    "attention_valiY = encode_output(attention_valiY, eng_vocab_size)\n",
    "\n",
    "attention_testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    "attention_testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "attention_testY = encode_output(attention_testY, eng_vocab_size)\n",
    "\n",
    "attention_model = define_attention_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
    "attention_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize defined model\n",
    "print(attention_model.summary())\n",
    "plot_model(attention_model, to_file='attention_model.png', show_shapes=True)\n",
    "\n",
    "# fit model\n",
    "filename = 'attention_model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "attention_history = attention_model.fit(attention_trainX, attention_trainY, epochs=30, batch_size=256, validation_data=(attention_valiX, attention_valiY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = attention_history.history['loss']\n",
    "val_loss = attention_history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ou94F5LLzG41"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTO7C1gFzXhS"
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-dGUQGSzq9P"
   },
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oC56ziVqztlj"
   },
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "\tprediction = model.predict(source, verbose=0)[0]\n",
    "\tintegers = [argmax(vector) for vector in prediction]\n",
    "\ttarget = list()\n",
    "\tfor i in integers:\n",
    "\t\tword = word_for_id(i, tokenizer)\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\ttarget.append(word)\n",
    "\treturn ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gm8veHBhzwL6"
   },
   "outputs": [],
   "source": [
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "  smoothie = SmoothingFunction().method4\n",
    "  actual, predicted = list(), list()\n",
    "  correct_num = 0\n",
    "  total = 0\n",
    "  for i, source in enumerate(sources):\n",
    "    # translate encoded source text\n",
    "    source = source.reshape((1, source.shape[0]))\n",
    "    translation = predict_sequence(model, eng_tokenizer, source)\n",
    "    raw_target, raw_src = raw_dataset[i]\n",
    "    total += 1\n",
    "    if translation == raw_target.lower():\n",
    "      correct_num += 1\n",
    "    if i < 10:\n",
    "      print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "    actual.append(raw_target.split())\n",
    "    predicted.append(translation.split())\n",
    "\t# calculate BLEU score\n",
    "  print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0), smoothing_function=smoothie))\n",
    "  print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie))\n",
    "  print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0), smoothing_function=smoothie))\n",
    "  print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie))\n",
    "  # calculate accuracy\n",
    "  print(\"absolute accuracy=[%f], \" %float(correct_num / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "EXv2hWNszw-O",
    "outputId": "c615630d-ef33-4d72-8982-37b108f682c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading baseline model:\n",
      "train\n",
      "src=[Du hast echt n Knall], target=[Youre such a weirdo], predicted=[youre have a weirdo]\n",
      "src=[Da sind wir], target=[Here we are], predicted=[were we are]\n",
      "src=[Er ist in meiner Klasse], target=[Hes in my class], predicted=[hes in my my]\n",
      "src=[Er hatte die richtige Idee], target=[He had the right idea], predicted=[he was the plan]\n",
      "src=[Tom kam gut zu Hause an], target=[Tom arrived home safely], predicted=[tom arrived home home]\n",
      "src=[Ich habe mit dem Rauchen aufgehort], target=[I quit smoking], predicted=[i quit smoking smoking]\n",
      "src=[Macht euch keine Gedanken Ich sage nichts], target=[Dont worry I wont tell], predicted=[dont worry i i say]\n",
      "src=[Tom zerriss den Scheck], target=[Tom ripped up the check], predicted=[tom ripped up the]\n",
      "src=[Er ist an dieser Krankheit gestorben], target=[He died of that disease], predicted=[he died his his disease]\n",
      "src=[Er hat sich den Arm ausgerenkt], target=[He dislocated his arm], predicted=[he dislocated his arm]\n",
      "BLEU-1: 0.052111\n",
      "BLEU-2: 0.000690\n",
      "BLEU-3: 0.009731\n",
      "BLEU-4: 0.015485\n",
      "absolute accuracy=[0.432657], \n",
      "test\n",
      "src=[Das ist nie passiert], target=[This never happened], predicted=[everyone never happened]\n",
      "src=[Ich frage mich was geschehen wird], target=[I wonder what will happen], predicted=[i wonder what what]\n",
      "src=[Horen Sie auf sich wie ein Kind aufzufuhren], target=[Stop acting like a baby], predicted=[stop acting like a baby]\n",
      "src=[Habt ihr sie gesehen], target=[Have you seen her], predicted=[have you see them]\n",
      "src=[Willst du mitkommen], target=[Do you want to come along], predicted=[do you want to join]\n",
      "src=[Ich wei wo sie wohnt], target=[I know where she lives], predicted=[i know where you lives]\n",
      "src=[Lass mich sehen], target=[Let me see], predicted=[let me see]\n",
      "src=[Ich will das Mittagessen heute auslassen], target=[I plan to skip lunch], predicted=[i want an skipping lunch]\n",
      "src=[Das werden wir noch sehen], target=[That remains to be seen], predicted=[well see it]\n",
      "src=[Man hat mich angeschossen], target=[Ive been shot], predicted=[she had me me]\n",
      "BLEU-1: 0.053517\n",
      "BLEU-2: 0.191846\n",
      "BLEU-3: 0.283664\n",
      "BLEU-4: 0.256697\n",
      "absolute accuracy=[0.109533], \n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "print()\n",
    "print(\"Loading baseline model:\")\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# test on some training sequences\n",
    "print('train')\n",
    "evaluate_model(model, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(model, eng_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading bidirectional model:\n",
      "train\n",
      "src=[Tom hat geschummelt], target=[Tom was cheating], predicted=[tom cheated]\n",
      "src=[Ich flehe dich an mir zu helfen], target=[I beg you to help me], predicted=[i beg you to help me]\n",
      "src=[Tom ist wutend], target=[Tom is furious], predicted=[tom is furious]\n",
      "src=[Wir haben alles gesehen], target=[We saw everything], predicted=[we saw everything]\n",
      "src=[Ich sagte ich erinnere mich nicht], target=[I said I didnt remember], predicted=[i said i didnt remember]\n",
      "src=[Sie sollten sich einen Tag freinehmen], target=[You should take a day off], predicted=[you should take a day off]\n",
      "src=[Es gibt keine andere Erklarung], target=[Theres no other explanation], predicted=[theres no no other]\n",
      "src=[Das ist die Kamera meiner Schwester], target=[Thats my sisters camera], predicted=[this my sisters sisters]\n",
      "src=[Nehmen Sie die nachste Strae rechts], target=[Take the next right], predicted=[take the next right]\n",
      "src=[Das war unverzeihlich], target=[That was unforgivable], predicted=[that was unforgivable]\n",
      "BLEU-1: 0.048958\n",
      "BLEU-2: 0.187549\n",
      "BLEU-3: 0.281999\n",
      "BLEU-4: 0.256604\n",
      "absolute accuracy=[0.479533], \n",
      "test\n",
      "src=[Kann jemand anderes antworten], target=[Can anybody else answer], predicted=[can anyone answer answer]\n",
      "src=[Das Rad wird durch Wasserkraft angetrieben], target=[Water power turns the wheel], predicted=[the back is back complete]\n",
      "src=[Tom lehnte sich an die Wand], target=[Tom leaned against the wall], predicted=[tom leaned on the wall wall]\n",
      "src=[Wir werden es uns ansehen], target=[Well take a look], predicted=[well get it]\n",
      "src=[Sie gewinnen], target=[Youre winning], predicted=[they winning]\n",
      "src=[Es ist sich niemand so ganz sicher], target=[Nobody is really sure], predicted=[it no no that true]\n",
      "src=[Maria hat kein Selbstwertgefuhl], target=[Mary has no selfesteem], predicted=[mary has not]\n",
      "src=[Ich besuchte mit Tom ein Konzert], target=[I went to a concert with Tom], predicted=[i went to with work tom]\n",
      "src=[Ich kam auf einen Gedanken], target=[I hit on an idea], predicted=[i was about]\n",
      "src=[Hat Tom etwas zu Abend gegessen], target=[Did Tom eat dinner], predicted=[did tom eaten dinner dinner]\n",
      "BLEU-1: 0.049230\n",
      "BLEU-2: 0.182429\n",
      "BLEU-3: 0.274385\n",
      "BLEU-4: 0.249228\n",
      "absolute accuracy=[0.184667], \n"
     ]
    }
   ],
   "source": [
    "# load bidirectional model\n",
    "print()\n",
    "print(\"Loading bidirectional model:\")\n",
    "bi_model = load_model('bi_model.h5')\n",
    "print('train')\n",
    "evaluate_model(bi_model, eng_tokenizer, bi_trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(bi_model, eng_tokenizer, bi_testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading attention model:\n",
      "train\n",
      "src=[Ich werde hier auf dich warten], target=[Ill wait for you here], predicted=[ill wait for you]\n",
      "src=[Tom ist ein Verschwender], target=[Tom is wasteful], predicted=[tom is wasteful]\n",
      "src=[Tom bat Maria um Hilfe], target=[Tom asked Mary for help], predicted=[tom asked mary for help]\n",
      "src=[Da haben Sie unrecht], target=[Youre wrong about that], predicted=[theyre wrong wrong]\n",
      "src=[Tom ist extrem schuchtern], target=[Tom is extremely shy], predicted=[tom is extremely shy]\n",
      "src=[Was wurdest du andern], target=[What would you change], predicted=[what would you change]\n",
      "src=[Ich werde nicht aufgeben], target=[Im not going to give up], predicted=[i not give to give]\n",
      "src=[Tom fuhlte sich gedemutigt], target=[Tom felt humiliated], predicted=[tom felt humiliated]\n",
      "src=[Ich bin mir nicht sicher], target=[I am not sure], predicted=[im not sure sure]\n",
      "src=[Wir sind Seelenverwandte], target=[We are soulmates], predicted=[we are soulmates]\n",
      "BLEU-1: 0.051564\n",
      "BLEU-2: 0.190536\n",
      "BLEU-3: 0.283677\n",
      "BLEU-4: 0.257337\n",
      "absolute accuracy=[0.494857], \n",
      "test\n",
      "src=[Wir mogen Musik], target=[We like music], predicted=[we like music]\n",
      "src=[Tom bat mich um Hilfe], target=[Tom asked for my help], predicted=[tom asked me for help help]\n",
      "src=[Sie ist kluger als er], target=[Shes smarter than him], predicted=[she smarter smarter he him]\n",
      "src=[Ich will die Wahrheit horen], target=[I want to hear the truth], predicted=[i want to the the truth]\n",
      "src=[Tom kusste Mary], target=[Tom kissed Mary], predicted=[tom kissed mary]\n",
      "src=[Das erklart alles], target=[This explains everything], predicted=[this explains everything]\n",
      "src=[Wir zahlen auf dich], target=[Were counting on you], predicted=[were coming for you]\n",
      "src=[Tom scharfte sein Messer], target=[Tom sharpened his knife], predicted=[tom sharpened his knife]\n",
      "src=[Tom starb an Krebs], target=[Tom died of cancer], predicted=[tom died in cancer]\n",
      "src=[Niemand glaubt mir], target=[No one believes me], predicted=[no believes believes]\n",
      "BLEU-1: 0.053371\n",
      "BLEU-2: 0.191620\n",
      "BLEU-3: 0.283483\n",
      "BLEU-4: 0.256570\n",
      "absolute accuracy=[0.140733], \n"
     ]
    }
   ],
   "source": [
    "# load attention model\n",
    "print()\n",
    "print(\"Loading attention model:\")\n",
    "attention_model = load_model('attention_model.h5', custom_objects={'AttentionL':AttentionL})\n",
    "print('train')\n",
    "evaluate_model(attention_model, eng_tokenizer, attention_trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(attention_model, eng_tokenizer, attention_testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW2DhSQO9bsy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer exported\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open('ger_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(ger_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('eng_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(eng_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"tokenizer exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WF_CSCE636_Project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
